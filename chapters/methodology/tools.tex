In this chapter, we will discuss the tools we used to perform our experiment. 
We used Python as the programming language to implement our code. We chose Python because of its popularity and easy syntax. There are also plenty of Python libraries like Tensorflow, Keras, and scikit-learn available to easily implement machine learning, deep-learning, natural language processing algorithms. Along with Python as the programming language, we also used the following programs, tools, and datasets to perform our experiment.
 \section{Tools}
\subsection{HCC}
Due to the high computation requirements for some dataset we needed a faster and reliable hardware. The Holland Computing Center (HCC) claim to be the fastest resource in the state of Nebraska. HCC provides these services to researcher and students associated with any campus of the University of Nebraska system. Some shared services are available for free and dedicated services can be obtained for a modest price. We used their servers to run our Jupyter notebooks.

\subsection{Jupyter Notebook}
Jupyter notebook is part of project Jupyter, which aims at providing an interactive interface for development across multiple platforms and programming languages. Jupyter's web interface supports data cleaning, data transformation, and visualization, numerical operations, etc. It allows us to create live code snippets and equations and shows results of inline computation right next to the code in the form of rich media (SVG, LaTeX, etc.). It combines two components: 
\begin{itemize}
  \item \textbf{A web application}: a web-based interactive tool to write code, markdown, etc. It also displays the rich media output.
  \item \textbf{Notebook documents}: a representation of all the content written and displayed using the web application.
\end{itemize}
Jupyter notebook is gaining rapid popularity in the field of data science for making sharing documentation and codes for replication very easy. In this project, we wrote the codes in python notebook, which can be accessed from our GitHub repository.

\subsection{Tensorflow}
% TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications
TensorFlow was developed as an open-source library at Google by their Brain team. It is used by many well-known companies like AMD, Uber, etc to develop machine learning models and perform complex numerical computations. Although TensorFlow can do complex numerical computations, it was designed mainly for developing deep learning models. It provides APIs for loading, manipulating, and using the datasets along with generating and using machine learning models. We used TensorFlow to implement the seven-layer neural network and convolutional neural network defined in section \ref{Algorithms}.

% TensorFlow\textsuperscript{TM} is an open source software library developed within Google's AI organization by the Google Brain team with a strong support for machine learning and deep learning. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. It is being used at a number of well known companies like Uber, Google, AMD, etc. for high performance numerical computation and machine learning. While TensorFlow is capable of handling a wide range of tasks, it is mainly designed for deep neural network models. It will serve as baseline to test the metamorphic relations identified in section \ref{MRused}. Tensorflow provides api for loading the MNIST dataset identified in section \ref{dataset}. We also used tensorflow to implement neural network and convolutional neural network defined in section \ref{Algorithms}

\subsection{Scikit-learn}
Scikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license.
It provides APIs to a range of supervised and unsupervised learning algorithms via a consistent interface in Python.









% \subsection{Docker}
% For replication of results. Image can be downloaded from dockerhub. Attached volume for persisting data.


