\section{Metamorphic Testing}\label{2.2MetamorphicTesting}

In the absence of a reliable oracle to indicate the correct output for arbitrary inputs, machine learning programs are often very hard to test. It is almost impossible to generate all the possible combinations of test cases to completely test a program. Thus, a lot of research is being conducted to develop more error-revealing test case selection strategies. A test case is called error-revealing if it is able to detect an error in the software otherwise it is labeled successful. Successful test case are the cases for which the program successfully computes the correct output. Since these test cases do not reveal any error, they are considered less important and are often not investigated further or, set aside for regression testing \cite{Zhou2004, Chen2003}.

Chen, Cheung, and Yiu \cite{Chen1998} first introduced the idea of metamorphic testing to make use of valuable information in successful test cases in order to answer the oracle problem. Metamorphic testing reuses successful test cases to generate followup test cases according to metamorphic relations. Thus, rather being a test selection strategy, metamorphic testing is used to generate new test cases whose output can easily be predicted \cite{Murphy2008}. A metamorphic relation(MR) is an expected relation among input and outputs of multiple executions of the target program \cite{Chen2003,Zhou2016}. Consider a function $f$ which produces the output $f(x)$ on input $x$. The metamorphic relations of the function can then be used to generate a transformation function $t$, which, when applied to input $x$ produces $t(x)$. The transformed input $t(x)$ can then be run through the function $f$ to generate the output $f(t(x))$. This $f(t(x))$ is then compared to the expected behaviour of $f$ on $t(x)$ from the metamorphic relation to find any error. \cite{Murphy2009}. 
To demonstrate a MR, consider a program that calculates the mean of a set of real numbers. Certain transformations of the input numbers will result in the same value for mean. An example of this transformation can be a permutation of the order of input. Since, this does not changes the number of elements in the input set or the value of any element, we can safely assume that the mean will remain same. Another transformation could be to multiply each number in the input set with -1. The new mean will be the negative value of the previous mean. In both the cases we can easily predict the output for the newly generated test cases. Thus, multiplication and permutation are metamorphic relations for this algorithm.

\subsection{Properties of a good metamorphic relation}
Segura et al. \cite{Segura2016} did an extensive review of metamorphic testing with 119 papers published between 1998 and 2015 to answer important research questions about origin, current state, and, future of metamorphic testing. They identified that the most popular use of metamorphic testing was in web services, followed by computer graphics, simulation and modelling, and, embedded systems. They also found some other domains of application like financial software, optimization programs, and encryption programs.
 
They also studied the properties of effective metamorphic relations. To select the most effective metamorphic relations to detect faults one must have.
\begin{itemize}
	\item A good understanding of the problem domain since good metamorphic relations are usually strongly inspired by the semantics of the program under test.
	\item Metamorphic relations that make execution of the follow-up test case as different as possible from the source test case.
	\item Metamorphic relations derived from specific parts of the system since they are more effective than those targeting the whole system.
	\item Formally described metamorphic relations. In particular, a metamorphic relation should be a 3-tuple composed of $i)$ relation between the inputs of the source and follow-up test cases, $ii)$ relation between the outputs of source and follow-up test cases, and $iii)$ program function.
\end{itemize}
Research from Chen et al. shows that metamorphic relations that makes the subsequent execution the most different from the initial execution have the best chances of revealing failure. Although, they did not explicitly define what is meant by "different" in terms of multiple execution \cite{Chen2003}.

The execution of a metamorphic test case is typically performed in two steps. First, a follow-up test case is generated by applying a transformation to the inputs of a source test case. Second, source and follow-up test cases are executed, checking whether their outputs violate the metamorphic relation. It should be noted that MT does not check the correctness of individual outputs. Instead, it checks the relations among several executions. Since no manual output predictions and comparisons are required, MT can be efficient and fully automated \cite{Segura2016}. Comparing the outputs of the morphed data still remains a challenge especially if the data set is large or not in human readable format.
% 	\subsection{Automatic System Testing of Programs without Test Oracles \cite{Murphy2009}}
A number of frameworks have been developed to address this issue and automate the process of metamorphic testing. Gotlieb and Botella \cite{Gotlieb2003} presented a framework called Automated Metamorphic Testing (AMT) to automatically generate test data for metamorphic relations. Given the source code of a program written in C and a metamorphic relation, AMT tries to find test cases that violate the relation. The underlying method is based on the translation of the code into an equivalent constraint logic program over finite domains. Other techniques like “special values” and random testing can also be used as source test cases for metamorphic testing. Genetic algorithms have also been used for the selection of source test cases, to maximize the paths traversed in the program under test. But, their focus was on generation of new test cases and not on verifying that the metamorphic properties hold after execution.
	
Murphy et al. \cite{Murphy2009} also demonstrated how metamorphic testing can be used to assess the quality of applications without test oracles.  They presented an approach called ``Automated Metamorphic System Testing'' to automate the metamorphic testing by considering the system as a black box and checking if the metamorphic properties holds after multiple executions of the system. In this model $i)$ Metamorphic properties are specified by the tester and applied to the input. $ii)$ A transformation of the input is also generated and the original input is fed into the application. $iii)$ The transformed input is fed into a separate instance of the application running in a separate sandbox. $iv)$ When the invocations are finished, the results are compared and if they do not match according to the specifications, there is an error. All a tester has to do is provide the metamorphic properties and does not require the knowledge of implementation.

In order to demonstrate Automated Metamorphic System Testing they created a framework called Amsterdam. The tool takes as inputs the program under test and a set of metamorphic relations, defined in an XML file. The XML specification consists of three parts: $i)$ how to transform the input, $ii)$ how to execute the program, and, $iii)$ how to compare the outputs. Then, Amsterdam automatically runs the program, applies the metamorphic relations and checks the results. 

While implementing Amsterdam framework, it became quite clear that small deviations in results calculations (like floating point operations) could cause a problem where exact results were expected. Also, many applications implements non-determinism for which outputs cannot be reliably predicted, hence, rendering metamorphic testing ineffective. To address this, they introduce a technique called "Heuristic Metamorphic Testing", based on the concept of "heuristic test oracles". Heuristic Metamorphic Testing reduces false positives and addresses non-determinism by allowing for small differences in outputs, in a meaningful way according to the application being used. If two outputs are close enough they are considered the same. The definition of close enough depends on the application and in complex applications checking semantic similarity may also be required. This approach also treats applications under test as black boxes and do not require detailed understanding of source code.
		
Although metamorphic testing presents a lot of opportunities to expand on the existing testing processes, they also have some limitations. Murphy, et al. \cite{Murphy2009} list some of the limitations of using metamorphic testing:
\begin{itemize}
	\item Manual transformation of large input data can be laborious and error-prone. They need special tools to transform the input.
	\item Comparing the outputs(some of which may be very large and/or in not human-readable format) of the input data can be tedious.
	\item Floating point calculations can also lead to imprecision even though the calculations are programmatically correct.
	\item Coming up with the initial test-cases is also a challenge as some defects may only occur under certain inputs.
\end{itemize}

Segura, et al. \cite{Segura2016} also identified some research challenges:
\begin{itemize}
	\item Lack of guidelines, with step-by-step process to guide testers, experts, and beginners, in the construction of good metamorphic relations.
	\item Prioritization and minimization of metamorphic relations: It is worth mentioning that test case minimization is a NP-hard problem and therefore heuristic techniques should be explored.
	\item Generation of likely metamorphic relations.
	\item Combination of metamorphic relations.
	\item Automated generation of best possible source test cases.
	\item Lack of metamorphic testing tools.
\end{itemize}
