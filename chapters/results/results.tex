In this section, we will discuss our findings after implementing the machine learning algorithms and metamorphic properties.

Accuracy is defined as the number of correct predictions made by the model with respect to the total number of predictions made. To evaluate the accuracy of our machine learning models, we first trained the models on the training data. The MNIST, Fashion-MNIST, and EMNIST-Letter training datasets have 55000, 55000, and 119800 training data, respectively. The training data consists of images and their corresponding labels, which are used as input to the algorithm to generate a model. Once we generated the trained models, we used the test data to calculate the accuracy of the models. The following graphs show the accuracy of the various models on the original test dataset.

\pgfplotstableread[row sep=\\,col sep=&]{
    interval & MNIST & Fashion & EMNIST-Letter \\
    CNN     & 97.01 & 83.56 & 78.20 \\
    NN     & 91.41 & 79.89 & 64.96 \\
    NB    & 80.85 & 65.6 & 57.81 \\
    KNN   & 97.28 & 85.24 & 86.25 \\
    SVM   & 95.47 & 84.56 & 81.25\\
    }\accuracy
    
\begin{center}
\begin{tikzpicture}
    \begin{axis}[
            ybar,
            bar width=.75cm,
            height=.5\textwidth,
            width=\textwidth,
            legend style={at={(0.5,1)},
                anchor=north,legend columns=-1},
            symbolic x coords={CNN,NN,NB,KNN, SVM},
            xtick=data,
            ytick={0,20,40,60,80,100},
            nodes near coords,
            nodes near coords align={vertical},
            ymin=0,ymax=120,
            ylabel={Accuracy},
            xlabel={Algorithms}
        ]
        \addplot table[x=interval,y=MNIST]{\accuracy};
        \addplot table[x=interval,y=Fashion]{\accuracy};
        \addplot table[x=interval,y=EMNIST]{\accuracy};
        \legend{MNIST, Fashion, EMNIST}
    \end{axis}
\end{tikzpicture}      
\end{center}{}
An interesting observation from the table above is that deep learning algorithms are not necessarily always the right choice when we are trying to maximize accuracy. Depending on the dataset, regular machine learning algorithms like KNN can also yield high accuracy and outperform deep learning algorithms in terms of accuracy.
In the following sections, we will discuss how the metamorphic transformations affected the accuracy of the models and what conclusions we can draw from it.
\section{Affect of metamorphic transformation on the accuracy of the models}
From the literature review, we saw that metamorphic testing could be an instrumental technique to test the correctness of a program. In this thesis, we will investigate the effect of the identified metamorphic properties on the accuracy of the machine learning algorithms. For each metamorphic property identified in \ref{identifyingMR}, we want to see how the accuracy of the models changes with the varying degree of transformation. We hypothesize that small changes to the input image should not affect the prediction of the model drastically. After creating a trained model with the training dataset, we applied the metamorphic properties on the training data to generate transformed versions of the test data. We calculated the following metrics to evaluate the effect of metamorphic relations on the machine learning algorithm we implemented. To tackle the stochastic nature of training a neural network model, we ran each of the above experiments ten times and calculated the average accuracy of the models on the transformed datasets.
\input{figures.tex}

\clearpage
\subsection{Robustness}

In the section \ref{Digit-by Accuracy} we saw that that the accuracy of the algorithms varied depending upon the transformation applied to the test data as well as the degree of the transformation. Robustness is the property of an algorithm whereby if the test data is "similar" to the training data then the testing error is also close to the training error \cite{Xu2012}. Thus, a robust algorithm should produce similar errors while predicting similar test data. In this section, we will be comparing the robustness of the five algorithms with respect to each other for different metamorphic relations and verify the accuracy of the recommendations we made in the table \ref{tbl:indexrecommendations}. For this we generated a new dataset with those recommendations and compared it's accuracy with the accuracy of the original dataset. To generate a balanced dataset of 5000 samples we randomly picked 100 transformed images from each transformation for every class label. This new test dataset was then tested for accuracy on the five algorithms we implemented. The bar graph below shows the accuracy of the new test dataset as compared to the original MNIST dataset.

\pgfplotstableread[row sep=\\,col sep=&]{
    Algorithm & MNIST & Transformed  \\
    CNN     & 97.01 & 95.2 \\
    NN     & 91.41 & 89.02 \\
    NB    & 80.85 & 78.76 \\
    SVM   & 95.47 & 90.98\\
    KNN   & 97.28 & 93.06\\
    }\Robustness
    
\begin{figure}[H]
\begin{tikzpicture}
    \begin{axis}[
            ybar,
            bar width=.75cm,
            height=.5\textwidth,
            width=\textwidth,
            legend style={at={(0.5,1)},
                anchor=north,legend columns=-1},
            symbolic x coords={CNN,NN,NB,KNN, SVM},
            xtick=data,
            ytick={0,20,40,60,80,100},
            nodes near coords,
            nodes near coords align={vertical},
            ymin=0,ymax=120,
            ylabel={Accuracy},
            xlabel={Algorithms}
        ]
        \addplot table[x=Algorithm,y=MNIST]{\Robustness};
        \addplot table[x=Algorithm,y=Transformed]{\Robustness};
        \legend{MNIST, Transformed Images}
    \end{axis}
\end{tikzpicture}      
\caption{Accuracy of tranformed dataset vs original dataset}
\label{img:transformedaccuracy}
\end{figure}

The more robust algorithm will have the accuracy of the transformed images closer to the accuracy of the original MNIST data. From the graph above we see that the convolutional neural network has a $1.81\%$ decrease in accuracy while the accuracy of the neural-network, NB, KNN, and, SVM decreased by $2.39\%$, $2.09\%$, $4.22\%$, and, $4.49\%$ respectively. Thus, among the algorithms we implemented the convolutional neural network is proven to be the most robust followed by Naive Bayes implementation. While the KNN and SVM implementations are the least robust.

In Section \ref{4.1.1} we discovered that the accuracy of the test data decreased as the degree of the transformation was increased. So a second way of looking at robustness is to look at transformations which can be applied to the dataset without lowering the accuracy of the model below 90 percent of the original value.




\import{chapters/results/}{tables.tex}

\newpage
\section{Discussion}
In this paper we identified five metamorphic properties "Rotation", "Shading", "Shearing", "Shifting the image along $x$ axis", and, "Shifting the image along $y$ axis" that can be used with image datasets. We then applied these metamorphic transformations to three datasets: MNIST, Fashion-MNIST, and, EMNIST. We then implemented five machine learning algorithms and measured the accuracy of the three datasets as well as the accuracy on the transformed dataset. We also investigated the accuracy of transformations on individual classes in the MNIST dataset and provided recommendations for creating follow up test cases from the MNIST dataset. These recommendations include the minimum and maximum values of transformations that can be used for the metamorphic properties. We also evaluated the robustness of the machine learning algorithms on these metamorphic properties. From this evaluation we found that convolutional neural-networks are more robust than the other machine learning algorithms we implemented. \\
This paper also makes the a methodological contribution where we have provided a set of functions on the project's github page to easily manipulate, and, transform image datasets for future research. 
% These functions can be used as frameworks to . 
Future researchers can utilize these functions to plugin more algorithms and metamorphic properties.

% Contributions:
% Methodological contribution where others can plugin more algors or MT.
% Experimental contribution:Which algo does better.


% Conclusions:

% Framework to apply MT in midst of distortions.
% CNN not so much better than others based on learning just from the dataset.

